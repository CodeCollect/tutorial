# 自定义损失函数

TensorFlow 不仅支持经典的损失的损失函数，还可以优化任意的自定义损失函数。

在预测商品销量时，如果预测多了（预测值比真实销量大），商家损失的是生产商品的成本；而如果预测少了（预测值比真实销量小），损失的则是商品的利润。

因为一般商品的成本和商品的利润不会严格相等，所以使用前面介绍的[经典损失函数：交叉熵](./cross-entropy.md)和[经典损失函数：均方差](./mean-squared-error.md)就不能够很好地实现最大化利润。

比如一个商品的成本是 1 元，但利润是 10 元，那么少预测一个就少挣 10 元；而多预测一个才少挣 1 元。如果神经网络模型最小化的是均方误差，那么很有可能此模型就无法最大化预期的利润。

为了最大化预期利润，需要将损失函数和利润直接联系起来。

注意，损失函数定义的是损失，所以要将利润最大化，定义的损失函数应该刻画成本或者代价。以下公式给出了一个当预测多于真实和预测少于真实值时有不同损失系数的损失函数：

$$
Loss(y, y')=\sum_{i=1}^nf(y_i,y'_i), f(x,y)=\left\{\begin{matrix}a(x-y),x>y\\ b(y-x),x\leqslant y\\\end{matrix}\right.
$$

和均方差公式类似， $y_i$ 为一个 batch 中第 i 个数据的正确答案， $y'_i$ 为神经网络得到的预测值， a 和 b 是常量。比如上面介绍的销量预测问题中， a 就等于 10 （正确答案多于预测答案的代价），而 b 等于 1 （正确答案少于预测答案的代价）。通过这个自定义损失函数的优化，模型提供的预测值就更有可能最大化收益。

在 TensorFlow 中，可以通过以下代码来实现这个损失函数：

```python
loss = tf.reduce_sum(tf.where(tf.greater(v1, v2), (v1-v2)*a, (v2-v1)*b))
```

---

参考文献：《[TensorFlow：实战Google深度学习框架（第二版）](https://book.douban.com/subject/30137062/)》
